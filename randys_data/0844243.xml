<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle><![CDATA[SGER:  Exploring Emotional Vocal Productions Through the Use of Real-Time Magnetic Resonance Imaging]]></AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>09/01/2008</AwardEffectiveDate>
<AwardExpirationDate>02/28/2010</AwardExpirationDate>
<AwardTotalIntnAmount>0.00</AwardTotalIntnAmount>
<AwardAmount>50000</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Tatiana Korelsky</SignBlockName>
<PO_EMAI>tkorelsk@nsf.gov</PO_EMAI>
<PO_PHON>7032928729</PO_PHON>
</ProgramOfficer>
<AbstractNarration><![CDATA[Humans use intricate vocal and visual orchestrations to encode and communicate intent and emotions. Understanding and utilizing these expressive emotional elements hence is key to facilitating any human experience, including for developing human-centered communication technologies.  The vocal instrument is central to the expressive human communication capability. While its use in speaking, singing and other forms of vocalizations have been studied well, the actual expressive mechanisms of vocal productions are less completely understood. For example, what vocal tract mechanisms do humans use to produce speech sounds conveying anger versus happiness? How do singers produce different sounds with different emotions? New technology tools, such as fast magnetic resonance imaging, combined with novel computational capabilities, such as statistical machine learning, offer ways for gaining insights into, and measuring and modeling, these processes in ways that were not possible before. &lt;br/&gt;&lt;br/&gt;This Small Grant for Exploratory Research  focuses on investigating the articulatory vocal production mechanisms of expressive human communication.  It has two specific near term goals.  The first goal aims at experimental data collection of emotional speech production using real-time magnetic resonance imaging. The goal focuses on pilot analysis of the collected data, both image and audio, and provide insights into the emotional modulation of speech mechanisms and its consequences on the audio signal.   The work will provide the necessary foundation for a detailed research study on emotional human speech production. &lt;br/&gt;&lt;br/&gt;The intellectual merit of the project lies in the use of novel methods for examining and modeling emotional speech production.  It aims to discover details of how the human vocal process is modulated to encode emotional expressions and how such knowledge   can be incorporated in the design of emotional speech processing and generation by the machine. Expressive aspects of information however have been largely ignored in the technology realm with the primary focus thus far put on content than style; human machine interfaces are limited in their emotional cognizance. The study of emotional human speech promises new directions in human language communication research and its applications. &lt;br/&gt;&lt;br/&gt;The interdisciplinary approach to the problem leads to its broad impact along several dimensions including the innovative experimental and computational approaches that can impact several disciplines including engineering, computer science, psychology and linguistics, the use of the project as a vehicle for graduate and undergraduate training, and the dissemination of novel imaging data that is hitherto not available in the scientific community. &lt;br/&gt;]]></AbstractNarration>
<MinAmdLetterDate>08/16/2008</MinAmdLetterDate>
<MaxAmdLetterDate>07/24/2009</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>0844243</AwardID>
<Investigator>
<FirstName>Shrikanth</FirstName>
<LastName>Narayanan</LastName>
<PI_MID_INIT>S</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Shrikanth S Narayanan</PI_FULL_NAME>
<EmailAddress><![CDATA[shri@sipi.usc.edu]]></EmailAddress>
<NSF_ID>000377152</NSF_ID>
<StartDate>08/16/2008</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of Southern California</Name>
<CityName>LOS ANGELES</CityName>
<ZipCode>900894304</ZipCode>
<PhoneNumber>2137407762</PhoneNumber>
<StreetAddress>3720 S FLOWER ST</StreetAddress>
<StreetAddress2><![CDATA[FL 3]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>California</StateName>
<StateCode>CA</StateCode>
<CONGRESSDISTRICT>37</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>CA37</CONGRESS_DISTRICT_ORG>
<ORG_UEI_NUM>G88KLJR3KYT5</ORG_UEI_NUM>
<ORG_LGL_BUS_NAME>UNIVERSITY OF SOUTHERN CALIFORNIA</ORG_LGL_BUS_NAME>
<ORG_PRNT_UEI_NUM/>
</Institution>
<Performance_Institution>
<Name><![CDATA[University of Southern California]]></Name>
<CityName>LOS ANGELES</CityName>
<StateCode>CA</StateCode>
<ZipCode>900894304</ZipCode>
<StreetAddress><![CDATA[3720 S FLOWER ST]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>California</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>37</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>CA37</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7495</Code>
<Text>Robust Intelligence</Text>
</ProgramElement>
<ProgramReference>
<Code>9215</Code>
<Text>HIGH PERFORMANCE COMPUTING SYSTEMS</Text>
</ProgramReference>
<ProgramReference>
<Code>9237</Code>
<Text>SMALL GRANTS-EXPLORATORY RSRCH</Text>
</ProgramReference>
<ProgramReference>
<Code>HPCC</Code>
<Text>HIGH PERFORMANCE COMPUTING &amp; COMM</Text>
</ProgramReference>
<Appropriation>
<Code>0108</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Fund>
<Code>01000809DB</Code>
<Name><![CDATA[NSF RESEARCH & RELATED ACTIVIT]]></Name>
<FUND_SYMB_ID>040100</FUND_SYMB_ID>
</Fund>
<FUND_OBLG>2008~50000</FUND_OBLG>
</Award>
</rootTag>
