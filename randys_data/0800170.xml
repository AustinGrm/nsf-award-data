<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle><![CDATA[Progressive Site Modeling with Videogrammetry]]></AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>08/01/2008</AwardEffectiveDate>
<AwardExpirationDate>12/31/2008</AwardExpirationDate>
<AwardTotalIntnAmount>231407.00</AwardTotalIntnAmount>
<AwardAmount>231407</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>07030000</Code>
<Directorate>
<Abbreviation>ENG</Abbreviation>
<LongName>Directorate For Engineering</LongName>
</Directorate>
<Division>
<Abbreviation>CMMI</Abbreviation>
<LongName>Div Of Civil, Mechanical, &amp; Manufact Inn</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Dennis Wenger</SignBlockName>
<PO_EMAI/>
<PO_PHON/>
</ProgramOfficer>
<AbstractNarration><![CDATA[The proposed research plans to evaluate the capability of a novel remote sensing method in acquiring time-dependent spatial data (4D surface) of construction sites for ?as-built? modeling. Under this method, video streams are initially collected from a calibrated set of high resolution video cameras that is progressively traversed around a construction site. The possible correspondences of each point in each video camera?s view are computed (epipolar lines) and the corresponding points are matched using a novel window similarity matching method that compares the video frame along each epipolar line. Based on each match and the camera calibration, the depth value of each point is computed, and the depth map (dense point cloud) of the scene is generated. In each subsequent frame, all points with a previously identified correspondence in the other video camera?s frame are tracked using established 2D point tracking techniques. This prevents redundant and computationally intensive epipolar line computation and correspondence matching. The resulting point cloud at each frame is then converted to a 3D surface using intelligent proximity algorithms, and the visual data are overlaid to produce a photorealistic, rendered 3D surface.&lt;br/&gt;&lt;br/&gt;The proposed method is significantly automated, allowing the user to reconstruct a scene or structure progressively and in real time, without the need for post-processing. It can also identify and track complex point clouds with a variable precision (according to the user needs). The data resolution is virtually limitless, since both macro and micro data sensing is possible by adjusting the distance of the sensor system to its targets and using the proper lenses. The equipment cost is two orders of magnitude less than the cost of a LiDAR scanner, and also compact, lightweight and highly portable. Thus, the immediate advantage that will result from this work is the ability to automate the 3D surface generation step of the ?as-built? model generation process and significantly reduce the cost for the necessary remote sensing equipment. Currently, engineers need to spend several days to post process the raw data and convert them to a basic 3D surface. Under this approach, engineers need only scan the desired site until the automatically generated 3D surface is consistent with their needs. This improvement is expected to open up new avenues for future research and enhancements that can ultimately achieve real-time model generation. It is therefore expected to significantly reduce the time and effort needed to create an ?as-built? model. This will increase the infiltration of innovative spatial modeling technologies to the AEC industry and allow its benefits to be realized by the majority of construction projects, especially by small projects, where&lt;br/&gt;]]></AbstractNarration>
<MinAmdLetterDate>07/18/2008</MinAmdLetterDate>
<MaxAmdLetterDate>07/18/2008</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.041</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>0800170</AwardID>
<Investigator>
<FirstName>Ioannis</FirstName>
<LastName>Brilakis</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Ioannis Brilakis</PI_FULL_NAME>
<EmailAddress><![CDATA[brilakis@gatech.edu]]></EmailAddress>
<NSF_ID>000307333</NSF_ID>
<StartDate>07/18/2008</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Regents of the University of Michigan - Ann Arbor</Name>
<CityName>ANN ARBOR</CityName>
<ZipCode>481091079</ZipCode>
<PhoneNumber>7347636438</PhoneNumber>
<StreetAddress>1109 GEDDES AVE, SUITE 3300</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>Michigan</StateName>
<StateCode>MI</StateCode>
<CONGRESSDISTRICT>06</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>MI06</CONGRESS_DISTRICT_ORG>
<ORG_UEI_NUM>GNJ7BBP73WE9</ORG_UEI_NUM>
<ORG_LGL_BUS_NAME>REGENTS OF THE UNIVERSITY OF MICHIGAN</ORG_LGL_BUS_NAME>
<ORG_PRNT_UEI_NUM/>
</Institution>
<Performance_Institution>
<Name><![CDATA[Regents of the University of Michigan - Ann Arbor]]></Name>
<CityName>ANN ARBOR</CityName>
<StateCode>MI</StateCode>
<ZipCode>481091079</ZipCode>
<StreetAddress><![CDATA[1109 GEDDES AVE, SUITE 3300]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Michigan</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>06</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>MI06</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>1631</Code>
<Text>CIS-Civil Infrastructure Syst</Text>
</ProgramElement>
<ProgramReference>
<Code>036E</Code>
<Text>CIVIL INFRASTRUCTURE</Text>
</ProgramReference>
<ProgramReference>
<Code>1057</Code>
<Text>CIS BASE RESEARCH</Text>
</ProgramReference>
<ProgramReference>
<Code>9146</Code>
<Text>MANUFACTURING BASE RESEARCH</Text>
</ProgramReference>
<ProgramReference>
<Code>CVIS</Code>
<Text>CIVIL INFRASTRUCTURE</Text>
</ProgramReference>
<ProgramReference>
<Code>MANU</Code>
<Text>MANUFACTURING</Text>
</ProgramReference>
<Appropriation>
<Code>0108</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Fund>
<Code>01000809DB</Code>
<Name><![CDATA[NSF RESEARCH & RELATED ACTIVIT]]></Name>
<FUND_SYMB_ID>040100</FUND_SYMB_ID>
</Fund>
<FUND_OBLG>2008~0</FUND_OBLG>
</Award>
</rootTag>
