<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>CAREER: Haptography: Capturing and Recreating the Rich Feel of Real Surfaces</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>07/15/2009</AwardEffectiveDate>
<AwardExpirationDate>06/30/2014</AwardExpirationDate>
<AwardTotalIntnAmount>499495.00</AwardTotalIntnAmount>
<AwardAmount>499495</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Ephraim Glinert</SignBlockName>
<PO_EMAI>eglinert@nsf.gov</PO_EMAI>
<PO_PHON>7032924341</PO_PHON>
</ProgramOfficer>
<AbstractNarration>This award is funded under the American Recovery and Reinvestment Act of 2009 (Public Law 111-5). &lt;br/&gt;&lt;br/&gt;The proposed research will address two fundamental questions in the field of haptics: How can we mathematically characterize the feel of real and virtual surfaces? and How can a computer-mediated interaction best duplicate the rich feel of a real surface? Specific contributions of this work will include the creation of hand-held instruments that accurately capture and re-create the broad-bandwidth experience of natural touch-based interactions with real object surfaces; the construction of a signal-processing pipeline that can use recorded motion data to derive perceptually relevant dynamic models for the tool-contact states of hovering, pressing, and traversing, plus the event-based transitions between these states; the generation of an interactive online database of haptographs for a wide variety of tool-surface pairings; evaluation of the benefits and drawbacks of the proposed approach to high-fidelity acceleration feedback for virtual environment rendering; and an understanding of the role of the human haptographer in these processes. In the domain of education, the specific contributions of this project will include improvements to the PI?s hands-on engineering mechanics course for first-year engineers; carefully guided involvement of a diverse range of undergraduate and graduate students in the proposed research endeavors; and the development of novel instructional methods and materials for the PI?s new graduate-level class on haptics research.&lt;br/&gt;&lt;br/&gt;The planned combination of research and education activities have numerous potential benefits for society and the student community in and around University of Pennsylvania. Particular positive ramifications of establishing the approach of haptography are to allow doctors and dentists to create haptic records of medical afflictions such as a decayed tooth surface to assist in diagnosis and patient health tracking; to improve the realism and consequent training efficacy of haptic surgical simulators and other computer-based education tools; to allow a wide range of people, such as museum goers and online shoppers, to touch realistic virtual copies of valuable items; to facilitate a haptographic approach to low-bandwidth and time-delayed teleoperation, as found in space exploration; and to enable new insights on human and robot touch capabilities.</AbstractNarration>
<MinAmdLetterDate>07/10/2009</MinAmdLetterDate>
<MaxAmdLetterDate>03/13/2014</MaxAmdLetterDate>
<ARRAAmount>499495</ARRAAmount>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>0845670</AwardID>
<Investigator>
<FirstName>Katherine</FirstName>
<LastName>Kuchenbecker</LastName>
<PI_MID_INIT>J</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Katherine J Kuchenbecker</PI_FULL_NAME>
<EmailAddress>kuchenbe@seas.upenn.edu</EmailAddress>
<NSF_ID>000465871</NSF_ID>
<StartDate>07/10/2009</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of Pennsylvania</Name>
<CityName>Philadelphia</CityName>
<ZipCode>191046205</ZipCode>
<PhoneNumber>2158987293</PhoneNumber>
<StreetAddress>Research Services</StreetAddress>
<StreetAddress2><![CDATA[3451 Walnut St, 5th Flr Franklin]]></StreetAddress2>
<CountryName>United States</CountryName>
<StateName>Pennsylvania</StateName>
<StateCode>PA</StateCode>
<CONGRESSDISTRICT>03</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>PA03</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>042250712</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>TRUSTEES OF THE UNIVERSITY OF PENNSYLVANIA, THE</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>042250712</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[University of Pennsylvania]]></Name>
<CityName>Philadelphia</CityName>
<StateCode>PA</StateCode>
<ZipCode>191046205</ZipCode>
<StreetAddress><![CDATA[Research Services]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Pennsylvania</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>03</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>PA03</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<FoaInformation>
<Code>0116000</Code>
<Name>Human Subjects</Name>
</FoaInformation>
<ProgramElement>
<Code>7367</Code>
<Text>HCC-Human-Centered Computing</Text>
</ProgramElement>
<ProgramReference>
<Code>1045</Code>
<Text>CAREER-Faculty Erly Career Dev</Text>
</ProgramReference>
<ProgramReference>
<Code>1187</Code>
<Text>PECASE- eligible</Text>
</ProgramReference>
<ProgramReference>
<Code>6890</Code>
<Text>RECOVERY ACT ACTION</Text>
</ProgramReference>
<ProgramReference>
<Code>7367</Code>
<Text>Cyber-Human Systems</Text>
</ProgramReference>
<ProgramReference>
<Code>9215</Code>
<Text>HIGH PERFORMANCE COMPUTING SYSTEMS</Text>
</ProgramReference>
<ProgramReference>
<Code>HPCC</Code>
<Text>HIGH PERFORMANCE COMPUTING &amp; COMM</Text>
</ProgramReference>
<Appropriation>
<Code>01R9</Code>
<Name>RRA RECOVERY ACT</Name>
<APP_SYMB_ID>040101</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2009~499495</FUND_OBLG>
</Award>
</rootTag>
