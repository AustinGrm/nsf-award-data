<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>RI-Small: Multi-level Priors for Multi-view Stereo</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>09/15/2008</AwardEffectiveDate>
<AwardExpirationDate>08/31/2012</AwardExpirationDate>
<AwardTotalIntnAmount>300000.00</AwardTotalIntnAmount>
<AwardAmount>316000</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Jie Yang</SignBlockName>
<PO_EMAI>jyang@nsf.gov</PO_EMAI>
<PO_PHON>7032924768</PO_PHON>
</ProgramOfficer>
<AbstractNarration>Humans are remarkably good at perceiving shape, even in cases where the image cues alone would seem to be insufficient.  For example, up to certain distortions, people can infer the structure of a scene from a single photograph.  Similarly, they can often estimate the shape of surfaces that are only partially visible, such as a chair that is half-occluded.  These remarkable abilities are due to the human capacity to combine visual cues with prior information about the shapes of objects and surfaces in the world.&lt;br/&gt;&lt;br/&gt;In computer vision, modern multi-view stereo algorithms that exploit very low-level cues now produce shape models that are proving to be nearly as accurate as laser scanners and are doing so in very unconstrained settings, e.g., using photos from Internet sharing sites.  However, these algorithms lack the other piece of the puzzle --- the ability of the human visual system to exploit prior information about scene shape.  &lt;br/&gt;&lt;br/&gt;In this work, the PIs focus on the particular domain of architectural scenes for which prior notions of shape are particularly applicable. Existing priors typically fall into two categories: low-level, usually a preference to reconstruct smooth surfaces, and high-level, such as model-based techniques that have parameterized templates for specific architectural features.  The PIs are exploring a range of priors between these extremes, significantly increasing the expressiveness of low-level priors and defining a set of mid-level priors.  The key ideas are to consider the differential properties of architectural surfaces (e.g., curvature behavior) and to exploit the symmetries that frequently occur in this setting.  The PIs are studying a range of reconstruction problems and applications, from single-view reconstruction to multi-view stereo, that exploit priors and prior selection.&lt;br/&gt;&lt;br/&gt;Finally, the PIs are evaluating the potential of these techniques to reconstruct detailed architectural models from street-level, aerial, and interior views from the Internet.  As part of this evaluation, they are obtaining ground truth laser scans and registered imagery to provide a benchmark for the research community.&lt;br/&gt;&lt;br/&gt;The outcome of this research, i.e., tools that can automatically reconstruct geometric models from large collections of images, will enable a host of important applications, ranging across 3D visualization, localization, communication, recognition, and cultural heritage, that go well beyond traditional computer vision problems and can have broad impacts for the population at large.&lt;br/&gt;&lt;br/&gt;  http://grail.cs.washington.edu/projects/cpc/&lt;br/&gt;&lt;br/&gt;</AbstractNarration>
<MinAmdLetterDate>08/29/2008</MinAmdLetterDate>
<MaxAmdLetterDate>05/12/2009</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>0811878</AwardID>
<Investigator>
<FirstName>Steven</FirstName>
<LastName>Seitz</LastName>
<PI_MID_INIT>M</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Steven M Seitz</PI_FULL_NAME>
<EmailAddress>seitz@cs.washington.edu</EmailAddress>
<NSF_ID>000195084</NSF_ID>
<StartDate>08/29/2008</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Brian</FirstName>
<LastName>Curless</LastName>
<PI_MID_INIT>L</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>Brian L Curless</PI_FULL_NAME>
<EmailAddress>curless@cs.washington.edu</EmailAddress>
<NSF_ID>000417360</NSF_ID>
<StartDate>08/29/2008</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of Washington</Name>
<CityName>Seattle</CityName>
<ZipCode>981950001</ZipCode>
<PhoneNumber>2065434043</PhoneNumber>
<StreetAddress>4333 Brooklyn Ave NE</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>Washington</StateName>
<StateCode>WA</StateCode>
<CONGRESSDISTRICT>07</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>WA07</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>605799469</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>UNIVERSITY OF WASHINGTON</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>042803536</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[University of Washington]]></Name>
<CityName>Seattle</CityName>
<StateCode>WA</StateCode>
<ZipCode>981950001</ZipCode>
<StreetAddress><![CDATA[4333 Brooklyn Ave NE]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>Washington</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>07</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>WA07</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7495</Code>
<Text>Robust Intelligence</Text>
</ProgramElement>
<ProgramReference>
<Code>0000</Code>
<Text>UNASSIGNED</Text>
</ProgramReference>
<ProgramReference>
<Code>7495</Code>
<Text>ROBUST INTELLIGENCE</Text>
</ProgramReference>
<ProgramReference>
<Code>9215</Code>
<Text>HIGH PERFORMANCE COMPUTING SYSTEMS</Text>
</ProgramReference>
<ProgramReference>
<Code>9251</Code>
<Text>REU SUPP-Res Exp for Ugrd Supp</Text>
</ProgramReference>
<ProgramReference>
<Code>HPCC</Code>
<Text>HIGH PERFORMANCE COMPUTING &amp; COMM</Text>
</ProgramReference>
<ProgramReference>
<Code>OTHR</Code>
<Text>OTHER RESEARCH OR EDUCATION</Text>
</ProgramReference>
<Appropriation>
<Code>0108</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0109</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2008~300000</FUND_OBLG>
<FUND_OBLG>2009~16000</FUND_OBLG>
</Award>
</rootTag>
