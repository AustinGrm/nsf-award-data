<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>III-CXT-Small: Collaborative Research: Structuring, Reasoning, and Querying</AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>09/01/2008</AwardEffectiveDate>
<AwardExpirationDate>08/31/2010</AwardExpirationDate>
<AwardTotalIntnAmount>0.00</AwardTotalIntnAmount>
<AwardAmount>115469</AwardAmount>
<AwardInstrument>
<Value>Continuing Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Sylvia Spengler</SignBlockName>
<PO_EMAI>sspengle@nsf.gov</PO_EMAI>
<PO_PHON>7032927347</PO_PHON>
</ProgramOfficer>
<AbstractNarration>Image data is of immense practical importance in medical informatics, and a subject of strong interest to researchers in industry and academia. While digital image databases are now prevalent in clinical and educational settings, and traditional means for interacting with and querying such collections can provide some level of useful functionality, there are few examples of systems that attempt to bridge the ?semantic gap.? The work proposed in this grant is a multi-institutional collaboration combining research in medical image processing, machine learning and pattern recognition, knowledge representation and querying, and evaluation by domain experts in the field, is intended to advance the state-of-the-art in this direction. The archive of 60,000 cervigram images assembled by the National Library of Medicine and National Cancer Institute is an ideal collection for this purpose. The NLM cervigram archive forms a narrow image domain that has a limited and predictable variability. In such cases, explicit representation of domain knowledge alleviates the semantic gap between the low-level sensory recordings of a scene (raw image data), and objects and processes implied from images (semantic interpretation). This research will follow an information hierarchy that proceeds from raw image data to low-level image features, recognition of objects and tissue types, knowledge-based reasoning about disease processes, and, finally, tools and visualizations to support diagnosis decisions by clinical and NLM/NCI collaborators. The research team will employ an underlying paradigm known as Computer-Assisted Visual Interactive Recognition, or CAVIAR, which considers the domain expert an integral part of the equation and attempts to optimize the performance of the complete human-machine system. &lt;br/&gt;&lt;br/&gt;Intellectual Merit &lt;br/&gt;&lt;br/&gt;Image content understanding is still considered a vexing open problem at the same time databases are growing rapidly in size and complexity. It is anticipated that this work will have a positive impact in areas relating to medical image analysis, including information extraction, organization, representation, and querying, as well as in training. &lt;br/&gt;&lt;br/&gt;Broader Impact &lt;br/&gt;&lt;br/&gt;Through the focus on the NLM/NCI cervigram archive, this research may help advance the role of cervicography as a more cost-effective procedure than pap smears and colposcopy in screening for cervical cancer. Results from this targeted-domain project could also illuminate gaps and help establish new priorities for research in broader domains such as multimedia content structuring, understanding, indexing, and retrieval.</AbstractNarration>
<MinAmdLetterDate>08/20/2008</MinAmdLetterDate>
<MaxAmdLetterDate>06/15/2009</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>0812124</AwardID>
<Investigator>
<FirstName>George</FirstName>
<LastName>Nagy</LastName>
<PI_MID_INIT/>
<PI_SUFX_NAME/>
<PI_FULL_NAME>George Nagy</PI_FULL_NAME>
<EmailAddress>nagy@ecse.rpi.edu</EmailAddress>
<NSF_ID>000177631</NSF_ID>
<StartDate>08/20/2008</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Rensselaer Polytechnic Institute</Name>
<CityName>Troy</CityName>
<ZipCode>121803522</ZipCode>
<PhoneNumber>5182766000</PhoneNumber>
<StreetAddress>110 8TH ST</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>New York</StateName>
<StateCode>NY</StateCode>
<CONGRESSDISTRICT>20</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>NY20</CONGRESS_DISTRICT_ORG>
<ORG_DUNS_NUM>002430742</ORG_DUNS_NUM>
<ORG_LGL_BUS_NAME>RENSSELAER POLYTECHNIC INSTITUTE</ORG_LGL_BUS_NAME>
<ORG_PRNT_DUNS_NUM>002430742</ORG_PRNT_DUNS_NUM>
</Institution>
<Performance_Institution>
<Name><![CDATA[Rensselaer Polytechnic Institute]]></Name>
<CityName>Troy</CityName>
<StateCode>NY</StateCode>
<ZipCode>121803522</ZipCode>
<StreetAddress><![CDATA[110 8TH ST]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>New York</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>20</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>NY20</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<ProgramElement>
<Code>7364</Code>
<Text>Info Integration &amp; Informatics</Text>
</ProgramElement>
<ProgramReference>
<Code>7364</Code>
<Text>INFO INTEGRATION &amp; INFORMATICS</Text>
</ProgramReference>
<ProgramReference>
<Code>9216</Code>
<Text>ADVANCED SOFTWARE TECH &amp; ALGOR</Text>
</ProgramReference>
<ProgramReference>
<Code>9251</Code>
<Text>REU SUPP-Res Exp for Ugrd Supp</Text>
</ProgramReference>
<ProgramReference>
<Code>HPCC</Code>
<Text>HIGH PERFORMANCE COMPUTING &amp; COMM</Text>
</ProgramReference>
<Appropriation>
<Code>0108</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Appropriation>
<Code>0109</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<FUND_OBLG>2008~55623</FUND_OBLG>
<FUND_OBLG>2009~59846</FUND_OBLG>
</Award>
</rootTag>
