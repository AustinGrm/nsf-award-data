<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle><![CDATA[CPA-G&amp;V:Collaborative Research: Visual Equivalence: A New Foundation for Perceptually-Based Rendering of Complex Scenes]]></AwardTitle>
<AGENCY>NSF</AGENCY>
<AwardEffectiveDate>08/01/2008</AwardEffectiveDate>
<AwardExpirationDate>07/31/2012</AwardExpirationDate>
<AwardTotalIntnAmount>125000.00</AwardTotalIntnAmount>
<AwardAmount>125000</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05010000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>CCF</Abbreviation>
<LongName>Division of Computing and Communication Foundations</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Lawrence Rosenblum</SignBlockName>
<PO_EMAI/>
<PO_PHON/>
</ProgramOfficer>
<AbstractNarration><![CDATA[&lt;br/&gt;Abstract&lt;br/&gt;PI: Kavita Bala (0811680)&lt;br/&gt;PI: James ferwerda (0811032)&lt;br/&gt;&lt;br/&gt;The goal of realistic imaging is to produce images that faithfully represent the appearance of the real world.  Assessing image fidelity is an important aspect of realistic imaging that has broad implications in both computer graphics and digital photography.  Recently perceptual metrics based on computational models of human vision have been used to characterize image fidelity; but these metrics typically characterize pixel-wise image differences. When we look at images we don?t see pixels, we see objects with distinct shapes, sizes, materials, and motions.  Therefore, there is a need for image fidelity metrics that characterize the appearance properties of objects. This project introduces a new standard for image fidelity called visual equivalence. Images are visually equivalent if they convey the same information about object appearance (shape, material, lighting), even if they are different pixel-by-pixel. This new standard fundamentally expands the scope of how to assess image fidelity, providing a metric that is based on higher-level properties of visual coding.&lt;br/&gt;&lt;br/&gt;This project seeks to understand and leverage the phenomenon of visual equivalence by: a) conducting a series of psychophysical experiments that develop a foundation for  visual  equivalence by exploring interactions between the geometry, material and illumination properties of objects in complex scenes;  b) developing visual equivalence predictors that apply to a wide range of scenes; and c) demonstrating the practical utility of the concept of visual equivalence in a range of applications including high-fidelity environment map compression and scalable rendering of complex scenes. The products of this research provide valuable new tools for addressing one of the grand challenges in computer graphics:  the high performance, high fidelity image synthesis of complex scenes.  Further, this new approach to image fidelity should have a significant impact beyond graphics in areas including 2d and 3d digital image acquisition, coding, compression, transmission, storage, and display.&lt;br/&gt;&lt;br/&gt;]]></AbstractNarration>
<MinAmdLetterDate>07/18/2008</MinAmdLetterDate>
<MaxAmdLetterDate>07/18/2008</MaxAmdLetterDate>
<ARRAAmount/>
<TRAN_TYPE>Grant</TRAN_TYPE>
<CFDA_NUM>47.070</CFDA_NUM>
<NSF_PAR_USE_FLAG>0</NSF_PAR_USE_FLAG>
<FUND_AGCY_CODE>4900</FUND_AGCY_CODE>
<AWDG_AGCY_CODE>4900</AWDG_AGCY_CODE>
<AwardID>0811032</AwardID>
<Investigator>
<FirstName>James</FirstName>
<LastName>Ferwerda</LastName>
<PI_MID_INIT>A</PI_MID_INIT>
<PI_SUFX_NAME/>
<PI_FULL_NAME>James A Ferwerda</PI_FULL_NAME>
<EmailAddress><![CDATA[jaf@cis.rit.edu]]></EmailAddress>
<NSF_ID>000197349</NSF_ID>
<StartDate>07/18/2008</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Rochester Institute of Tech</Name>
<CityName>ROCHESTER</CityName>
<ZipCode>146235603</ZipCode>
<PhoneNumber>5854757987</PhoneNumber>
<StreetAddress>1 LOMB MEMORIAL DR</StreetAddress>
<StreetAddress2/>
<CountryName>United States</CountryName>
<StateName>New York</StateName>
<StateCode>NY</StateCode>
<CONGRESSDISTRICT>25</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_ORG>NY25</CONGRESS_DISTRICT_ORG>
<ORG_UEI_NUM>J6TWTRKC1X14</ORG_UEI_NUM>
<ORG_LGL_BUS_NAME>ROCHESTER INSTITUTE OF TECHNOLOGY</ORG_LGL_BUS_NAME>
<ORG_PRNT_UEI_NUM/>
</Institution>
<Performance_Institution>
<Name><![CDATA[Rochester Institute of Tech]]></Name>
<CityName>ROCHESTER</CityName>
<StateCode>NY</StateCode>
<ZipCode>146235603</ZipCode>
<StreetAddress><![CDATA[1 LOMB MEMORIAL DR]]></StreetAddress>
<CountryCode>US</CountryCode>
<CountryName>United States</CountryName>
<StateName>New York</StateName>
<CountryFlag>1</CountryFlag>
<CONGRESSDISTRICT>25</CONGRESSDISTRICT>
<CONGRESS_DISTRICT_PERF>NY25</CONGRESS_DISTRICT_PERF>
</Performance_Institution>
<FoaInformation>
<Code>0000912</Code>
<Name>Computer Science</Name>
</FoaInformation>
<FoaInformation>
<Code>0116000</Code>
<Name>Human Subjects</Name>
</FoaInformation>
<ProgramElement>
<Code>7352</Code>
<Text>COMPUTING PROCESSES &amp; ARTIFACT</Text>
</ProgramElement>
<ProgramReference>
<Code>9218</Code>
<Text>BASIC RESEARCH &amp; HUMAN RESORCS</Text>
</ProgramReference>
<ProgramReference>
<Code>HPCC</Code>
<Text>HIGH PERFORMANCE COMPUTING &amp; COMM</Text>
</ProgramReference>
<Appropriation>
<Code>0108</Code>
<Name>NSF RESEARCH &amp; RELATED ACTIVIT</Name>
<APP_SYMB_ID>040100</APP_SYMB_ID>
</Appropriation>
<Fund>
<Code>01000809DB</Code>
<Name><![CDATA[NSF RESEARCH & RELATED ACTIVIT]]></Name>
<FUND_SYMB_ID>040100</FUND_SYMB_ID>
</Fund>
<FUND_OBLG>2008~125000</FUND_OBLG>
</Award>
</rootTag>
